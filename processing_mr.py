import numpy as np
import pandas as pd
import sklearn 

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

X_app = pd.read_csv("/Users/hayato/Downloads/train_x.csv") # 説明変数のインポート
y_app = pd.read_csv("/Users/hayato/Downloads/train_y.csv") # 目的変数のインポート

X_app = X_app.dropna(how="all",axis=1) #全てがNaNのデータ列を消去

X_app = X_app[["職場の様子","（紹介予定）入社後の雇用形態","勤務地固定",
               "休日休暇(月曜日)","（派遣先）配属先部署　男女比　男","大手企業","週1日からOK",
               "交通費別途支給","（派遣先）配属先部署　人数","残業月20時間以上","1日7時間以下勤務OK",
               "ミドル（40〜）活躍中","ルーティンワークがメイン","短時間勤務OK(1日4h以内)","駅から徒歩5分以内",
              "対象者設定　年齢下限","学校・公的機関（官公庁）","土日祝のみ勤務","Wordのスキルを活かす",
              "給与/交通費　給与支払区分","勤務地　最寄駅1（分）","CAD関連のスキルを活かす","派遣スタッフ活躍中",
               "固定残業制","大量募集","公開区分","20代活躍中","Accessのスキルを活かす","検索対象エリア",
              "就業形態区分","休日休暇(火曜日)","平日休みあり","勤務地　最寄駅2（駅からの交通手段）",
              "30代活躍中","フラグオプション選択","期間・時間　勤務期間","派遣形態","週2・3日OK",
              "勤務先公開","Excelのスキルを活かす","16時前退社OK","正社員登用あり","残業月20時間未満",
              "英語力不要","休日休暇(日曜日)","雇用形態","Dip JobsリスティングS","社員食堂あり","資格取得支援制度あり",
              "対象者設定　年齢上限","10時以降出社OK","社会保険制度あり","英語以外の語学力を活かす","休日休暇(祝日)",
               "外資系企業","服装自由","PowerPointのスキルを活かす","（派遣先）配属先部署　男女比　女","残業月10時間未満",
              "休日休暇(土曜日)","履歴書不要","休日休暇(木曜日)","研修制度あり","（派遣先）配属先部署　平均年齢","英語力を活かす",
               "DTP関連のスキルを活かす","会社概要　業界コード","勤務地　都道府県コード","PCスキル不要","車通勤OK","制服あり",
              "給与/交通費　給与上限","休日休暇(水曜日)","仕事の仕方","勤務地　最寄駅1（駅からの交通手段）","紹介予定派遣",
              "シフト勤務","経験者優遇","週4日勤務","未経験OK","土日祝休み","給与/交通費　交通費","新卒・第二新卒歓迎","休日休暇(金曜日)",
              "産休育休取得事例あり","扶養控除内","給与/交通費　給与下限","対象者設定　性別","WEB登録OK","オフィスが禁煙・分煙",
               "勤務地　市区町村コード","勤務地　最寄駅2（分）","残業なし"]] #数値データのみを抽出

X_app = X_app.dropna(how="any",axis=1) #NaNを含む列の消去


y_app = y_app.drop(["お仕事No."],axis=1) # お仕事No列を消去

X_array = np.array(X_app) #説明変数のデータを配列に変換
y_array = np.array(y_app) #目的変数のデータを配列に変換

X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.4, random_state=0) #データを分割

rfr = RandomForestRegressor(random_state=0) #モデルを生成

rfr.fit(X_train, y_train) #学習処理

y_pred = rfr.predict(X_test) #データ予測処理

np.sqrt(mean_squared_error(y_pred, y_test))  #RMSE導出による誤差計算処理

#ここまでが回帰モデル生成

x_ans = pd.read_csv("/Users/hayato/Downloads/test_x.csv")

df = pd.DataFrame({"お仕事No.": [], "応募数 合計": []})

df["お仕事No."] = x_ans["お仕事No."]

x_ans = x_ans[["職場の様子","（紹介予定）入社後の雇用形態","勤務地固定",
               "休日休暇(月曜日)","（派遣先）配属先部署　男女比　男","大手企業","週1日からOK",
               "交通費別途支給","（派遣先）配属先部署　人数","残業月20時間以上","1日7時間以下勤務OK",
               "ミドル（40〜）活躍中","ルーティンワークがメイン","短時間勤務OK(1日4h以内)","駅から徒歩5分以内",
              "対象者設定　年齢下限","学校・公的機関（官公庁）","土日祝のみ勤務","Wordのスキルを活かす",
              "給与/交通費　給与支払区分","勤務地　最寄駅1（分）","CAD関連のスキルを活かす","派遣スタッフ活躍中",
               "固定残業制","大量募集","公開区分","20代活躍中","Accessのスキルを活かす","検索対象エリア",
              "就業形態区分","休日休暇(火曜日)","平日休みあり","勤務地　最寄駅2（駅からの交通手段）",
              "30代活躍中","フラグオプション選択","期間・時間　勤務期間","派遣形態","週2・3日OK",
              "勤務先公開","Excelのスキルを活かす","16時前退社OK","正社員登用あり","残業月20時間未満",
              "英語力不要","休日休暇(日曜日)","雇用形態","Dip JobsリスティングS","社員食堂あり","資格取得支援制度あり",
              "対象者設定　年齢上限","10時以降出社OK","社会保険制度あり","英語以外の語学力を活かす","休日休暇(祝日)",
               "外資系企業","服装自由","PowerPointのスキルを活かす","（派遣先）配属先部署　男女比　女","残業月10時間未満",
              "休日休暇(土曜日)","履歴書不要","休日休暇(木曜日)","研修制度あり","（派遣先）配属先部署　平均年齢","英語力を活かす",
               "DTP関連のスキルを活かす","会社概要　業界コード","勤務地　都道府県コード","PCスキル不要","車通勤OK","制服あり",
              "給与/交通費　給与上限","休日休暇(水曜日)","仕事の仕方","勤務地　最寄駅1（駅からの交通手段）","紹介予定派遣",
              "シフト勤務","経験者優遇","週4日勤務","未経験OK","土日祝休み","給与/交通費　交通費","新卒・第二新卒歓迎","休日休暇(金曜日)",
              "産休育休取得事例あり","扶養控除内","給与/交通費　給与下限","対象者設定　性別","WEB登録OK","オフィスが禁煙・分煙",
               "勤務地　市区町村コード","勤務地　最寄駅2（分）","残業なし"]]

x_ans = x_ans.dropna(how="all",axis=1)
x_ans = x_ans.dropna(how="any",axis=1)
x_ans = x_ans.drop(columns=x_ans.select_dtypes(include='object').columns)

x_ans = np.array(x_ans)

y_pred2 = rfr.predict(x_ans)

df["応募数 合計"] = y_pred2

df.to_csv("appication_sum.csv",index=False)